{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Food Recommender (based off Burpple Reviews)\n",
    "### By: Team Omnomnom \n",
    "\n",
    "#### Annabella Lee, Bernice Tan, Fernanda Tan, Rachel Khong\n",
    "\n",
    "## Contents\n",
    "+ Part 1: Web Scraping\n",
    "+ Part 2: Data Preparation\n",
    "    + Cleaning\n",
    "    + Rating\n",
    "+ Part 3: Telegram Bot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from time import sleep\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chrome Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_options = webdriver.ChromeOptions()\n",
    "adblock = r'C:\\Users\\user\\AppData\\Local\\Google\\Chrome\\User Data\\Profile 2\\Extensions\\gighmmpiobklfepjocnamgkkbiglidom\\4.15.0_0'\n",
    "chrome_options.add_argument(\"load-extension=\" + adblock)\n",
    "\n",
    "chromedriver = r'C:\\Users\\user\\Documents\\Scraping\\chromedriver.exe'\n",
    "\n",
    "driver = webdriver.Chrome(executable_path=chromedriver,options=chrome_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get list of places (the urls) from a neighbourhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(r'https://www.burpple.com/search/sg?q=Bugis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load more until no more\n",
    "print(datetime.now())\n",
    "while True:\n",
    "    try:\n",
    "        load_more = WebDriverWait(driver, 10).until(\n",
    "              EC.element_to_be_clickable((By.ID, \"masonryViewMore-link\")))\n",
    "        actions = ActionChains(driver)\n",
    "        actions.move_to_element(load_more).click(load_more).perform()\n",
    "        sleep(2)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        break\n",
    "    \n",
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = []\n",
    "link_element = driver.find_elements_by_css_selector(\"div[class='searchVenue-header card-item card-item--header']>a\")\n",
    "for i in link_element:\n",
    "    link.append(i.get_attribute(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lk = pd.DataFrame(link)\n",
    "lk.to_csv(\"links.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping for the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = []\n",
    "places = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in link:\n",
    "    driver.get(url)\n",
    "    actions = ActionChains(driver)\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            load_more = WebDriverWait(driver, 5).until(EC.element_to_be_clickable((By.ID, \"load-more-reviews\")))\n",
    "            actions.move_to_element(load_more).click().perform()\n",
    "        except TimeoutException:\n",
    "            break\n",
    "    \n",
    "    sleep(5)\n",
    "    \n",
    "    place = driver.find_element_by_css_selector(\"h1[class='venue-title']>a\").text\n",
    "    \n",
    "    address = driver.find_element_by_css_selector(\"div[class='venue-details__item-body']>p\").text\n",
    "    address = address.replace(\"\\n\",\" \")\n",
    "    \n",
    "    venue_tag = []\n",
    "    venue_tags = driver.find_elements_by_css_selector(\"a[class='venue-tag']\")\n",
    "    for tag in venue_tags:\n",
    "        venue_tag.append(tag.text)\n",
    "        \n",
    "    url = driver.current_url\n",
    "    \n",
    "    places.append((place, address, venue_tag, url))\n",
    "    \n",
    "    cards = driver.find_elements_by_css_selector(\"div[class='food card feed-item']\")\n",
    "    for card in cards:\n",
    "        user_url = card.find_element_by_css_selector(\"div[class='card-item-set--link-title']>a\").get_attribute(\"href\")\n",
    "        username = user_url.replace(\"https://www.burpple.com/@\",\"\")\n",
    "        \n",
    "        try:\n",
    "            review = card.find_element_by_css_selector(\"div[class='food-description-body']>p\").text\n",
    "        except NoSuchElementException:\n",
    "            review = \"None\"\n",
    "        \n",
    "        reviews.append((place, username, review))\n",
    "    \n",
    "    sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rv = pd.DataFrame(reviews)\n",
    "rv.to_csv(\"reviews_bugis.csv\", header = ['Place', 'Username', 'Review'], index=False)\n",
    "\n",
    "pl = pd.DataFrame(places)\n",
    "pl.to_csv(\"places_bugis.csv\", header = ['Place', 'Address', 'Tags', 'url'], index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from snownlp import SnowNLP\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = pd.read_csv(\"places-bugis.csv\")\n",
    "rv = pd.read_csv(\"reviews-bugis.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "pl.drop_duplicates(keep=\"first\", inplace = True)\n",
    "rv.drop_duplicates(keep=\"first\", inplace = True)\n",
    "\n",
    "# Remove rows with no review (no body text)\n",
    "rv = rv[rv.Review != 'None']\n",
    "\n",
    "# Remove rows with review with no alphabets\n",
    "rv =  rv[rv['Review'].str.contains('[A-Za-z]')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15071 reviews to to work on.\n"
     ]
    }
   ],
   "source": [
    "print(len(rv),\"reviews to to work on.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get only the polarity of sentiment. Change the score to be upon 5\n",
    "rv['rating-textblob'] = rv['Review'].apply(lambda Review: (TextBlob(Review).sentiment.polarity+1)*2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get only the compound score. Change the score to be upon 5\n",
    "rv['rating-vader'] = rv['Review'].apply(lambda Review: (SentimentIntensityAnalyzer().polarity_scores(Review)['compound']+1)*2.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some examples on the sentiment scoring differences between TextBlob and VADER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Food was good and delicious with generous portions. If anyone who planned to used Burpple, please ask the staff before you order. Because I failed to use it although that day was not the exclusion day listed by the Burpple but told that the restaurant was having in house event. Kinda disappointed, I did not enjoy anything from the event also ‚òπÔ∏è. So, don't want to say much about it. \n",
      "Rating (TextBlob): 2.6875 \n",
      "Rating (VADER): 0.6637499999999998\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "print(rv.iloc[n,2], \"\\nRating (TextBlob):\", rv.iloc[n,3], \"\\nRating (VADER):\", rv.iloc[n,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output:**<br>\n",
    "Food was good and delicious with generous portions. If anyone who planned to used Burpple, please ask the staff before you order. Because I failed to use it although that day was not the exclusion day listed by the Burpple but told that the restaurant was having in house event. Kinda disappointed, I did not enjoy anything from the event also ‚òπÔ∏è. So, don't want to say much about it. <br>\n",
    "Rating (TextBlob): 2.6875 <br>\n",
    "Rating (VADER): 0.6637499999999998<br>\n",
    "<br>\n",
    "**Comment:** Reviewer complimented the food, but in only one sentence. In comparison, his complaint was much longer which VADER took into consideration for the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bourbon Pecan Pie-The Winner! Seriously, sooo good 4.5/5 \n",
      "Rating (TextBlob): 2.9583333333333335 \n",
      "Rating (VADER): 4.356\n"
     ]
    }
   ],
   "source": [
    "n = 38\n",
    "print(rv.iloc[n,2], \"\\nRating (TextBlob):\", rv.iloc[n,3], \"\\nRating (VADER):\", rv.iloc[n,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output:**<br>\n",
    "Bourbon Pecan Pie-The Winner! Seriously, sooo good 4.5/5 <br>\n",
    "Rating (TextBlob): 2.9583333333333335 <br>\n",
    "Rating (VADER): 4.356<br>\n",
    "<br>\n",
    "**Comment:** The rating by VADER is actually pretty close to what user had explicitly rated in his review. Either VADER is good or reviewer is good at expressing what he feels in words. Most possibly both!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ordered a Rosy Nose ($9.80), Salmon & Dill Quiche ($7), Salted Caramel Cheesecake ($7) and Galaxy Rainbow Cheesecake ($8). \n",
      "Rating (TextBlob): 3.75 \n",
      "Rating (VADER): 2.5\n"
     ]
    }
   ],
   "source": [
    "n = 4646\n",
    "print(rv.iloc[n-1,2], \"\\nRating (TextBlob):\", rv.iloc[n-1,3], \"\\nRating (VADER):\", rv.iloc[n-1,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output:**<br>\n",
    "Ordered a Rosy Nose (\\\\$9.80), Salmon & Dill Quiche (\\\\$7), Salted Caramel Cheesecake (\\\\$7) and Galaxy Rainbow Cheesecake (\\\\$8). <br>\n",
    "Rating (TextBlob): 3.75 <br>\n",
    "Rating (VADER): 2.5<br>\n",
    "<br>\n",
    "**Comment:** Purely stating what food they ordered and the price of it gives a neutral rating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final bits to put together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the ratings by TextBlob, rename the one by VADER as the one we want to use\n",
    "rv.drop(columns='rating-textblob', inplace=True)\n",
    "rv.rename(columns={'rating-vader':'Rating'}, inplace=True)\n",
    "\n",
    "# Getting the mean rating of each place\n",
    "temp = rv.groupby(['Place'])['Rating'].mean().to_frame()\n",
    "pl = pd.merge(pl, temp, on=\"Place\")\n",
    "\n",
    "# Round Rating to 2 d.p.\n",
    "pl['Rating'] = pl['Rating'].round(decimals=2)\n",
    "\n",
    "# Remove the [''] in the Tags column e.g. ['Desserts'] to Desserts\n",
    "pl['Tags'] = pl['Tags'].str.replace(r\"[\", \"\")\n",
    "pl['Tags'] = pl['Tags'].str.replace(r\"]\", \"\")\n",
    "pl['Tags'] = pl['Tags'].str.replace(r\"'\", \"\")\n",
    "\n",
    "# Tokenize tags to new dataframe\n",
    "pl_tokens = pd.DataFrame()\n",
    "pl_tokens['tags_tokenize'] = pl['Tags'].str.lower()\n",
    "pl_tokens['tags_tokenize'] = pl_tokens['tags_tokenize'].str.replace(r\",\", \"\")\n",
    "pl_tokens['tags_tokenize'] = pl_tokens['tags_tokenize'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.to_csv(\"places-bugis-ratings.csv\", index=False)\n",
    "pl_tokens.to_csv(\"places-bugis-tags-tokens.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'', 'fine dining', 'pasta', 'mexican', 'cheap & good', 'buffets', 'french', 'dinner with drinks', 'breakfast & brunch', 'bubble tea', 'ice cream & yoghurt', 'chinese', 'indonesian', 'fast food', 'cafes & coffee', 'newly opened', 'korean', 'korean desserts', 'ramen', 'chicken rice', 'japanese', 'mediterranean', 'waffles', 'supper', 'burgers', 'bread', 'takeaway available', 'turkish', 'zi char', 'bak kut teh', 'desserts', 'taiwanese', 'korean bbq', 'hidden gem', 'rainy day comforts', 'chirashi', 'cakes', 'italian', 'fruit tea', 'peranakan', 'salads', 'pizza', 'vegetarian', 'western', 'malay', 'sandwiches', 'soup', 'thai', 'late night', 'nasi lemak', 'middle eastern', 'european', 'burpple guides', 'steamboat', 'bars', 'dim sum', 'steak', 'healthier choice', '1-for-1 deals', 'halal', 'indian', 'seafood', 'kopitiam', 'sushi', 'date night', 'spanish', 'vietnamese', 'healthy', 'hawker food', 'korean fried chicken', 'local delights', 'great view', 'interesting', 'bbq', 'craft beer', 'cocktails', 'good for groups'}\n",
      "Total: 77 tags\n"
     ]
    }
   ],
   "source": [
    "# all the tags available\n",
    "all_tags = set()\n",
    "pl['Tags'].str.lower().str.split(', ').apply(all_tags.update)\n",
    "print(all_tags)\n",
    "print(\"Total:\",len(all_tags),\"tags\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Telegram Bot (@nom_what_bot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-22 06:33:22,772 - telegram.ext.updater - INFO - Received signal 2 (SIGINT), stopping...\n",
      "2020-07-22 06:33:31,544 - telegram.ext.updater - WARNING - Exiting immediately!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import time\n",
    "import logging\n",
    "from telegram import ReplyKeyboardMarkup\n",
    "from telegram.ext import (Updater, CommandHandler, MessageHandler, Filters,\n",
    "                          ConversationHandler)\n",
    "\n",
    "df_places = pd.read_csv(\"places-bugis-ratings.csv\")\n",
    "tag_tokens = pd.read_csv(\"places-bugis-tags-tokens.csv\")\n",
    "\n",
    "# Enable logging\n",
    "logging.basicConfig(format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "                    level=logging.INFO)\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "START_ANOT, RECOMMEND, END_ANOT = range(3)\n",
    "\n",
    "yes_no_keyboard = [['No', 'Yes']]\n",
    "yes_no_markup = ReplyKeyboardMarkup(yes_no_keyboard, one_time_keyboard=True)\n",
    "\n",
    "more_done_keyboard = [['No, not yet! (refine further)', 'Yeah, done!']]\n",
    "more_done_markup = ReplyKeyboardMarkup(more_done_keyboard, one_time_keyboard=True)\n",
    "\n",
    "def counts(row, tokens_filtered):\n",
    "    row_string = row.values[0]\n",
    "    cnt = 0\n",
    "    for x in tokens_filtered:\n",
    "        cnt = cnt + row_string.count(x)\n",
    "    return cnt\n",
    "\n",
    "def start(update, context):    \n",
    "    user = update.message.from_user # Get user's name\n",
    "    # Send a greeting\n",
    "    context.bot.send_message(chat_id=update.effective_chat.id, text=\"Omnomnom üç™ \"+user.first_name)\n",
    "    update.message.reply_text(\n",
    "        \"Need help deciding where to eat?\",\n",
    "        reply_markup=yes_no_markup)\n",
    "    return START_ANOT\n",
    "\n",
    "def yes_start(update, context):\n",
    "    update.message.reply_text('Alright! Whatchu feeling? \\nKeyword Examples: Pasta / Sushi / Dim Sim / Steak / etc. ')\n",
    "    return RECOMMEND\n",
    "\n",
    "def no_start(update, context):\n",
    "    update.message.reply_text(\"Okay that's fine. Use /start when you need help again :)\")\n",
    "    return ConversationHandler.END\n",
    "    \n",
    "def recommend(update, context):\n",
    "    text = update.message.text\n",
    "    \n",
    "    tokens = word_tokenize(text.lower())\n",
    "    ps = PorterStemmer()\n",
    "    tokens_filtered = [ps.stem(x) for x in tokens if x not in stopwords.words('english') and bool(re.search(\"[-0123456789`>(</',;:!?.)&]\", x))==False]\n",
    "    \n",
    "    df_places['match_counts'] = tag_tokens.apply(lambda row: counts(row, tokens_filtered), axis=1)\n",
    "    df_places.sort_values(by = ['match_counts', 'Rating'], ascending=False, inplace=True)\n",
    "    df_places.reset_index(drop = True, inplace=True)\n",
    "    \n",
    "    time.sleep(1)\n",
    "    # Place, Rating, Location, Tags, url\n",
    "    context.bot.send_message(\n",
    "        chat_id=update.effective_chat.id,\n",
    "        disable_web_page_preview=True,\n",
    "        text=\n",
    "        \"1. \"+df_places.iloc[0][0]+\"\\nRating: \"+str(df_places.iloc[0][4])+\"\\n\"+df_places.iloc[0][1]+\"\\nRelated Tags: \"+df_places.iloc[0][2]+\"\\n\"+df_places.iloc[0][3]+\"\\n\"+\"\\n\"+\n",
    "        \"2. \"+df_places.iloc[1][0]+\"\\nRating: \"+str(df_places.iloc[1][4])+\"\\n\"+df_places.iloc[1][1]+\"\\nRelated Tags: \"+df_places.iloc[1][2]+\"\\n\"+df_places.iloc[1][3]+\"\\n\"+\"\\n\"+\n",
    "        \"3. \"+df_places.iloc[2][0]+\"\\nRating: \"+str(df_places.iloc[2][4])+\"\\n\"+df_places.iloc[2][1]+\"\\nRelated Tags: \"+df_places.iloc[2][2]+\"\\n\"+df_places.iloc[2][3]+\"\\n\"+\"\\n\"+\n",
    "        \"4. \"+df_places.iloc[3][0]+\"\\nRating: \"+str(df_places.iloc[3][4])+\"\\n\"+df_places.iloc[3][1]+\"\\nRelated Tags: \"+df_places.iloc[3][2]+\"\\n\"+df_places.iloc[3][3]+\"\\n\"+\"\\n\"+\n",
    "        \"5. \"+df_places.iloc[4][0]+\"\\nRating: \"+str(df_places.iloc[4][4])+\"\\n\"+df_places.iloc[4][1]+\"\\nRelated Tags: \"+df_places.iloc[4][2]+\"\\n\"+df_places.iloc[4][3]\n",
    "    )\n",
    "    \n",
    "    time.sleep(1)\n",
    "    update.message.reply_text(\n",
    "        'Done making up your mind on where to eat already? Or refine your recommendations further?',\n",
    "        reply_markup=more_done_markup)\n",
    "    return END_ANOT\n",
    "\n",
    "def more_keyword(update, context):\n",
    "    update.message.reply_text(\"Okay more! Tell me more keywords to refine your recommendations.\")\n",
    "    return RECOMMEND\n",
    "\n",
    "def done(update, context):\n",
    "    update.message.reply_text(\"Nice to have helped! Use /start when you need help again :)\")\n",
    "    return ConversationHandler.END\n",
    "\n",
    "def main():\n",
    "    # Create the Updater and pass it your bot's token.\n",
    "    # Make sure to set use_context=True to use the new context based callbacks\n",
    "    # Post version 12 this will no longer be necessary\n",
    "    updater = Updater(telegram-bot-token, use_context=True)\n",
    "\n",
    "    # Get the dispatcher to register handlers\n",
    "    dp = updater.dispatcher\n",
    "\n",
    "    # Add conversation handler with the states CHOOSING, TYPING_CHOICE and TYPING_REPLY\n",
    "    conv_handler = ConversationHandler(\n",
    "        entry_points=[CommandHandler('start', start)],\n",
    "\n",
    "        states={\n",
    "            START_ANOT: [MessageHandler(Filters.regex(re.compile('(yes|yas|yea|yeah|ye)', re.IGNORECASE)),\n",
    "                                        yes_start),\n",
    "                        MessageHandler(Filters.regex(re.compile('(no|nah)', re.IGNORECASE)),\n",
    "                                       no_start)\n",
    "                        ],\n",
    "            RECOMMEND: [MessageHandler(Filters.text,\n",
    "                                       recommend)\n",
    "                       ],\n",
    "            END_ANOT: [MessageHandler(Filters.regex(re.compile('^(No, not yet! (refine further)|more)$', re.IGNORECASE)),\n",
    "                                      more_keyword),\n",
    "                       MessageHandler(Filters.regex(re.compile('^(Yeah, done!|done)$', re.IGNORECASE)),\n",
    "                                      done),\n",
    "                      ],\n",
    "        },\n",
    "\n",
    "        fallbacks=[MessageHandler(Filters.regex('^Done$'), done)]\n",
    "    )\n",
    "\n",
    "    dp.add_handler(conv_handler)\n",
    "\n",
    "    # Start the Bot\n",
    "    updater.start_polling()\n",
    "\n",
    "    # Run the bot until you press Ctrl-C or the process receives SIGINT,\n",
    "    # SIGTERM or SIGABRT. This should be used most of the time, since\n",
    "    # start_polling() is non-blocking and will stop the bot gracefully.\n",
    "    updater.idle()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Place</th>\n",
       "      <th>Address</th>\n",
       "      <th>Tags</th>\n",
       "      <th>url</th>\n",
       "      <th>Rating</th>\n",
       "      <th>match_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Blanco Court Fried Fish Noodles</td>\n",
       "      <td>325 Beach Road Singapore 199559</td>\n",
       "      <td>Rainy Day Comforts, Soup, Hawker Food</td>\n",
       "      <td>https://www.burpple.com/blanco-court-fish-soup</td>\n",
       "      <td>3.75</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Angel Horse Teochew Fish Soup (Albert Centre M...</td>\n",
       "      <td>270 Queen Street #01-95 Albert Centre Market &amp;...</td>\n",
       "      <td>Rainy Day Comforts, Hawker Food</td>\n",
       "      <td>https://www.burpple.com/angel-horse-teochew-fi...</td>\n",
       "      <td>4.79</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Xun Wei Hotpot</td>\n",
       "      <td>28 Liang Seah Street Singapore 189049</td>\n",
       "      <td>Rainy Day Comforts, Buffets, Supper, Chinese, ...</td>\n",
       "      <td>https://www.burpple.com/xun-wei-hotpot</td>\n",
       "      <td>4.63</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Beauty Nutritious Soup (Bugis Junction)</td>\n",
       "      <td>200 Victoria Street #03-30 Bugis Junction Food...</td>\n",
       "      <td>Soup, Hawker Food</td>\n",
       "      <td>https://www.burpple.com/beauty-nutritious-soup...</td>\n",
       "      <td>4.41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kuan Kuan Spicy Hotpot &amp; Nourishing Soup</td>\n",
       "      <td>32 Liang Seah Street Singapore 189053</td>\n",
       "      <td>Rainy Day Comforts, Chinese</td>\n",
       "      <td>https://www.burpple.com/kuan-kuan-spicy-hotpot</td>\n",
       "      <td>4.41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Place  \\\n",
       "0                    Blanco Court Fried Fish Noodles   \n",
       "1  Angel Horse Teochew Fish Soup (Albert Centre M...   \n",
       "2                                     Xun Wei Hotpot   \n",
       "3            Beauty Nutritious Soup (Bugis Junction)   \n",
       "4           Kuan Kuan Spicy Hotpot & Nourishing Soup   \n",
       "\n",
       "                                             Address  \\\n",
       "0                    325 Beach Road Singapore 199559   \n",
       "1  270 Queen Street #01-95 Albert Centre Market &...   \n",
       "2              28 Liang Seah Street Singapore 189049   \n",
       "3  200 Victoria Street #03-30 Bugis Junction Food...   \n",
       "4              32 Liang Seah Street Singapore 189053   \n",
       "\n",
       "                                                Tags  \\\n",
       "0              Rainy Day Comforts, Soup, Hawker Food   \n",
       "1                    Rainy Day Comforts, Hawker Food   \n",
       "2  Rainy Day Comforts, Buffets, Supper, Chinese, ...   \n",
       "3                                  Soup, Hawker Food   \n",
       "4                        Rainy Day Comforts, Chinese   \n",
       "\n",
       "                                                 url  Rating  match_counts  \n",
       "0     https://www.burpple.com/blanco-court-fish-soup    3.75             2  \n",
       "1  https://www.burpple.com/angel-horse-teochew-fi...    4.79             1  \n",
       "2             https://www.burpple.com/xun-wei-hotpot    4.63             1  \n",
       "3  https://www.burpple.com/beauty-nutritious-soup...    4.41             1  \n",
       "4     https://www.burpple.com/kuan-kuan-spicy-hotpot    4.41             1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for testing\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "df_places = pd.read_csv(\"places-bugis-ratings.csv\")\n",
    "tag_tokens = pd.read_csv(\"places-bugis-tags-tokens.csv\")\n",
    "\n",
    "def counts(row, tokens_filtered):\n",
    "    row_string = row.values[0]\n",
    "    cnt = 0\n",
    "    for x in tokens_filtered:\n",
    "        cnt = cnt + row_string.count(x)\n",
    "    return cnt\n",
    "\n",
    "def recommend():\n",
    "    text=\"some hot soup for the rainy day?\" # user input test\n",
    "    \n",
    "    tokens = word_tokenize(text.lower())\n",
    "    ps = PorterStemmer()\n",
    "    tokens_filtered = [ps.stem(x) for x in tokens if x not in stopwords.words('english') and bool(re.search(\"[-0123456789`>(</',;:!?.&)]\", x))==False]\n",
    "    \n",
    "    df_places['match_counts'] = tag_tokens.apply(lambda row: counts(row, tokens_filtered), axis=1)\n",
    "    df_places.sort_values(by = ['match_counts', 'Rating'], ascending=False, inplace=True)\n",
    "    df_places.reset_index(drop = True, inplace=True)\n",
    "    one = df_places.iloc[0][0]\n",
    "\n",
    "recommend()\n",
    "df_places.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
